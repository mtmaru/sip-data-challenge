# SIP Data Challenge 1st Place Solution

## コンテストの概要

### 背景

[公式サイト](https://sites.google.com/view/sipdatachallenge/) より引用：

> 内閣府・戦略的イノベーション創造プログラム (SIP) 第2期 ビッグデータ・AIを活用したサイバー空間基盤技術 (管理法人：NEDO) に採択された「エビデンスに基づくテーラーメイド教育の研究開発 」の研究では、教育・学習支援システムを利用したログデータの分析を実施しております。そこで今回、デジタル教材の閲覧履歴データを用いて成績を予測し、その精度を競う「教育データ解析チャレンジコンテスト」を開催することに致しました。これは、エビデンスに基づくテーラーメイド教育の実現を目指して、教育データの分析技術を、コンペティションを通して社会全体で向上していくことを目的としています。

### 入力

デジタル教材の閲覧ログデータ。  
※データの公開が禁止されているため、ここでは [公式ライブラリのドキュメント](https://limu.ait.kyushu-u.ac.jp/~openLA/tutorial_files/tutorial_event_stream.html) から読み取れる情報のみ記載。

* 主キー
    * eventtime：操作日時
    * userid：学生ID
    * contentsid：教材ID
    * pageno：ページ番号
* 閲覧ログ
    * operationname：操作の種類 (教材を開いた、次のページに移動した、など)
    * marker：マーカーの種類
    * memo_length：メモの長さ
    * devicecode：デバイスの種類

### 出力

総合成績 (0点～100点の100段階)

### 学習データとテストデータの分割

* 学習データ：2020年度に受講した学生10,000人
* テストデータ：2021年度に受講した学生100人

### 評価指標

コース開始から5週経過時点、10週経過時点、15週経過時点のデータから予測した総合成績のRMSE。  
※各時点で求めたRMSEの平均をとるのか、各時点の予測結果を集めてRMSEを求めるのかは不明。  
※また、学生100人が各時点で共有なのか異なるのかも不明。

このような評価指標を採用した理由はアナウンスされていないが、おそらく成績の悪い学生を早期に発見して介入することを目指しているためだと思う。

### 評価手順

参加者はプログラムを提出し、運営者がテストデータに対するRMSEを求める。  
ただし、再現性を確保するため、参加者はプログラムをインストールしたDockerイメージを提出する。  
テストデータは非公開で、参加者には動作確認用のダミーデータのみが配布される。

## 解法

### データ拡張

途中経過における予測に対応させるため、学習データ (15週経過時点のデータ) から疑似的に5週経過時点のデータと10週経過時点のデータを生成し、学習データに加えた。

### 特徴抽出

主な仮説：

* 仮説1：成績上位者に特有の操作パターンがある。
    * 例）下位者は一方向にページを送り続けるが、上位者は頻繁にページをジャンプする、など。
* 仮説2：好成績を収めるうえで重要な教材やページがある。
    * 例）易しい教材がある、テストに出る内容が書かれているページがある、など。

仮説に対応する特徴量：

* 仮説1：成績上位者に特有の操作パターンがある (※1、※2)。
    * 操作の種類のn-gram (1-gram、2-gram、3-gram) 別の操作数
    * マーカーの種類別の操作数
    * メモの長さ
    * 操作時間
    * 操作別の操作時間
    * デバイスの種類別の操作数
    * 時間別の操作数
    * 曜日別の操作数
    * 週別の操作数
* 仮説2：好成績を収めるうえで重要な教材やページがある。
    * 各教材の閲覧フラグ
    * 教材別の操作数
    * 教材別・ページ番号別の操作数
    * 教材別・ページ番号別の滞在時間
* その他
    * 予測時点フラグ (コース開始から5週経過時点、10週経過時点、15週経過時点)

※1 受講した教材の数の影響を除くため、まず教材別に操作数をカウントし、その値を教材で集約した。  
※2 集約は、`min` `median` `max` `mean` `std` `sum` を用いた。 

### 特徴選択

Null importanceを用いて、約17,000個の特徴量から約650個の重要な特徴量を抽出した。

### モデル

LightGBM

### 後処理

予測結果が0を下回る場合は0に、100を超える場合は100に置き換えた。

テストデータに閲覧ログのない学生 (テストだけ受けた学生) がいる可能性を考慮し、該当する学生の予測結果を定数に置き換えた。提出したプログラムのうちテストデータに対するRMSEの最も小さいもので順位を競うルールであったことから、0点・25点・50点・75点・100点のいずれかで予測結果を置き換えたプログラム5通りを作成し、提出した。75点で置き換えたプログラムが選ばれたことから、テストデータに閲覧ログがない学生がいることと、それらの学生の総合成績が平均75点前後であることがわかった。

### 評価

学習データとテストデータの分け方を変えて、ホールドアウト検証を10回繰り返し、その平均値で評価した。

1. 5週経過時点のデータ、10週経過時点のデータ、15週経過時点のデータを生成する。
2. 各データから100人ずつ、計300人を抽出し、テストデータにする。残りを学習データにする。
3. 学習データでモデルを学習させる。
4. テストデータの総合成績を予測し、RMSEを求める。
5. 1-4を10回繰り返し、RMSEの平均を求める。

### 参考にした解法

* [2019 Data Science Bow 1st Place Solution - Kaggle](https://www.kaggle.com/c/data-science-bowl-2019/discussion/127469)

## 分析結果

### RMSEの推移

* 公式のサンプルコードのモデルをSVMからLightGVMに置き換え：(?) → 約16
* データ拡張：約16 → 約14
* 操作の種類のn-gram別の操作数、マーカーの種類別の操作数、メモの長さを追加：約14 → 約12
* 各教材の閲覧フラグ、教材別の操作数、教材別・ページ番号別の操作数を追加：約12 → 約10
* デバイスの種類別の操作数、時間別の操作数、曜日別の操作数、週別の操作数を追加：特に大きな変化なし
* 操作時間や滞在時間を追加：特に大きな変化なし
* Null importanceによる特徴選択を追加：約10 → 約9

### モデルの解釈

[第35回教育機関DXシンポ](https://www.nii.ac.jp/event/other/decs/#edx35)を参照。

* 映像：https://youtu.be/e1agQWSLILw
* 資料：https://www.nii.ac.jp/event/upload/20210625-10_Maruyama.pdf

## 実行方法

### ビルド

```
docker build . -t sipdatachallenge
```

### 学習

```
docker run -v ${PWD}/data:/data -v ${PWD}/model:/model sipdatachallenge bash /app/train.sh
```

### 予測

```
docker run -v ${PWD}/data:/data -v ${PWD}/model:/model sipdatachallenge bash /app/evaluate.sh
```

### SHAP値の確認

```
docker run -v ${PWD}/data:/data -v ${PWD}/model:/model -p 8888:8888 -it sipdatachallenge jupyter notebook --allow-root --ip=* --no-browser
```
